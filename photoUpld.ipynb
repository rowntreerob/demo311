{"cells":[{"cell_type":"markdown","metadata":{"id":"fwoesLvSSdSx"},"source":["# Point & Shoot pothole reports via AI\n","This presents an AI model, trained for image classification in a [notebook format](https://www.dataquest.io/blog/jupyter-notebook-tutorial/) accessible to those interested in learning more about adapting media uploads to leverage AI and location in photos. The demo directs your execution of code step-by-step, automatically interpreting photos as they upload to the cloud. In order to work with a photo, while on a phone, simply snap a photo and a webapp submits it to the AI - No more scrolling a long list of issue types, just point and shoot. For the purposes of this demo being done on a laptop however, accessing a photo needs to workaround the fact that on laptops, cameras function, integrate differently. Here we need a download plus upload step to proxy for a camera snapping a photo. With access to an image in this example, location is retreived from the image and,  AI determines issue-type with a model trained on photos of various issues:\n","\n","1.   graffiti\n","2.   encampment\n","3.   garbage\n","4.   mural\n","\n","are 4 categories covered in the trained AI model. This example shows classification on the 4 issue types as well as GPS and address interpretation using meta-data from the photo itself.\n","##A sample Photo\n"," Here is a graffiti photo, including the street number (2933). In lieu of a phone's camera (not part of this excercise) simulate camera activity with download/upload in this example. After you complete the cycle of running all the cells (download, upload , GPS, address, type classification ) on the provided photo, you may return to the **Upload a photo** step only this time you may select from your photos any that you took or that you want to interrogate location and or type classification. Just repeat the steps below on the new photo ( step 2 only has to be run a single time and can be omitted in subsequent cycles).\n","\n","![sample 1](https://awsgcpupld-production.up.railway.app/pics/rclass_1.jpg)\n","\n","##Instructions to complete this excercise\n","1. download this photo - right clik on it then \"save image as.. \"\n","2. run the cell installing EXIF component\n","3. UPLOAD to colab, the photo just downloaded by running cell \"UPLOAD\"\n","4. run the 2 cells below that to get latitude , longitude and Address\n","5. run image classification cell to get the type of photo and issue type\n"]},{"cell_type":"markdown","metadata":{"id":"0Fcethtrqpmq"},"source":["##Note on running a cell\n","Cells in Colab notebooks have icons in the far upper left of the cell. A mouseover on each icon will display details of instructions on the controls that you use within cells in a notebook. Once selected, runnable cells have a grey triangle icon in small black circle. Clik it to run a cell. When complete, observe the bottom row of the cell where output of the cell appears.\n","\n","![run a cell](https://awsgcpupld-production.up.railway.app/pics/runColab.png)\n","\n","##Install EXIF module"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8928,"status":"ok","timestamp":1689640992456,"user":{"displayName":"Robert Rowntree","userId":"00753641935888348574"},"user_tz":420},"id":"mRi7bR_qScUE","outputId":"0564ff71-4060-483e-9f88-b1ea124de448"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting exif\n","  Downloading exif-1.6.0-py3-none-any.whl (30 kB)\n","Collecting plum-py<2.0.0,>=0.5.0 (from exif)\n","  Downloading plum_py-0.8.6-py3-none-any.whl (69 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.9/69.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: plum-py, exif\n","Successfully installed exif-1.6.0 plum-py-0.8.6\n"]}],"source":["# run this cell one-time to install software in CoLab sandbox\n","!pip install exif"]},{"cell_type":"markdown","metadata":{"id":"tTkaXKSnwCsf"},"source":["##UPLOAD a photo for input in cells below\n","A file chooser like this one allows a choice:  \n","- image from your photoroll / gallery\n","- open camera to take new photo\n","\n","The first time, for best results you can select the same downloaded image from above ( with graffiti ) as it is known to contain gps coordinates for the **photo gps** step below.\n","Once you have completed the cycle of notebook cells below, you may return to this cell and upload from whichever method you prefer. Remember the pathname of the file - used as input in subsequent steps in the notebook"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":92},"executionInfo":{"elapsed":34292,"status":"ok","timestamp":1689641026735,"user":{"displayName":"Robert Rowntree","userId":"00753641935888348574"},"user_tz":420},"id":"fgUFc_WtXJc4","outputId":"3b14c771-63be-4fd5-905b-464f0768b658"},"outputs":[{"data":{"text/html":["\n","     <input type=\"file\" id=\"files-b19dafc0-216f-4836-8e8c-b8be5de69a93\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-b19dafc0-216f-4836-8e8c-b8be5de69a93\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Saving qa_1.jpg to qa_1.jpg\n","User uploaded file \"qa_1.jpg\" with length 1482965 bytes\n"]}],"source":["#select an input image using the button for \"choose files\"\n","from google.colab import files\n","\n","uploaded = files.upload()\n","\n","for fn in uploaded.keys():\n","  fname = fn\n","  y=len(uploaded[fn])\n","  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n","      name=fn, length=len(uploaded[fn])))\n","\n","if y>2950000: print('downscale this image before its classified using downscale cell')"]},{"cell_type":"code","source":["from PIL import Image\n","\n","if y>2950000:\n","  print('file downsize image ')\n","  name,ext = os.path.splitext(fname)\n","  nwname = name + \"-sm\" + ext\n","  image = Image.open(fname)\n","  imgsml = image.resize((1000, 800))\n","  imgsml.save(nwname)"],"metadata":{"id":"lan732psNS75"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-ZAPyYYdvDNw"},"source":["##Interpret the Photo's GPS\n","metadata of the photo includes latitude/ longitude that can be read using \"EXIF\" software. Prints out GPS coordinate values ( latitude, longitude )"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":400,"status":"ok","timestamp":1689641032333,"user":{"displayName":"Robert Rowntree","userId":"00753641935888348574"},"user_tz":420},"id":"lQUZHOc9Uxcc","outputId":"f95faa50-8b9f-405f-db96-36d5e1998447"},"outputs":[{"name":"stdout","output_type":"stream","text":["lat: 37.75251388888889, long: -122.41395555555556\n"]}],"source":["from exif import Image\n","# using the uploaded image above as input\n","# call  gps parse functions for latitude / longitude from image data\n","# 2 functions defined below are used by stmt at the bottom \"image_coordinates\"\n","def decimal_coords(coords, ref):\n"," decimal_degrees = coords[0] + coords[1] / 60 + coords[2] / 3600\n"," if ref == 'S' or ref == 'W':\n","     decimal_degrees = -decimal_degrees\n"," return decimal_degrees\n","\n","def image_coordinates(img_path):\n","    coords = (0,0)\n","    with open(img_path, 'rb') as src:\n","        img = Image(src)\n","    if img.has_exif:\n","        try:\n","            img.gps_longitude\n","            coords = (decimal_coords(img.gps_latitude,\n","                      img.gps_latitude_ref),\n","                      decimal_coords(img.gps_longitude,\n","                      img.gps_longitude_ref))\n","        except AttributeError:\n","            print ('No Coordinates')\n","    else:\n","        print ('The Image has no EXIF information')\n","    return coords\n","\n","# Step 1:  file from above to funtion that gets gps\n","respGps = image_coordinates(fname)\n","# format the response into variables ref'd by cell below\n","lat,long = respGps\n","print(f\"lat: {lat}, long: {long}\")\n"]},{"cell_type":"markdown","metadata":{"id":"W1jwhgEyv0Ke"},"source":["##Google maps address  \n"," get a proper street address from the lat/ long coordinate values above by calling a service that implements the map feature (coordinate-to-street-address). Lists street address"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":401},"executionInfo":{"elapsed":14,"status":"error","timestamp":1694129845776,"user":{"displayName":"","userId":""},"user_tz":420},"id":"aTwAC3XlixUB","outputId":"c040db5e-8be6-4ed8-e949-f02a0e462767"},"outputs":[{"output_type":"error","ename":"InvalidSchema","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidSchema\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-b62567a12a72>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mjson_res\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"data\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m         \u001b[0;31m# Get the appropriate adapter to use\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m         \u001b[0madapter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         \u001b[0;31m# Start time (approximately) of the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget_adapter\u001b[0;34m(self, url)\u001b[0m\n\u001b[1;32m    792\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0;31m# Nothing matches :-/\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 794\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mInvalidSchema\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No connection adapters were found for {url!r}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    795\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    796\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidSchema\u001b[0m: No connection adapters were found for \"('https://demo311-production.up.railway.app/addr/37.752756/-122.409781',)\""]}],"source":["#if you do not have a google maps api key use this version\n","import requests\n","# a proxy to gogleapis.com hides the api-key. use the cell below if u have key\n","# Step 2: Construct the request and make the request\n","url = f'https://demo311-production.up.railway.app/addr/37.752756/-122.409781',\n","\n","\n","\n","resp = requests.get(url).json()\n","json_res = resp\n","print(resp[\"data\"])"]},{"cell_type":"markdown","metadata":{"id":"k5XI_w2tA9qV"},"source":["##Roboflow API - image classification\n","A trained AI model inspects the photo, applying an issue-type label ( garbage, encampment, graffiti).\n","```\n","from roboflow import Roboflow\n","\n","rf = Roboflow(api_key={API_KEY})\n","project = rf.workspace().project(\"org311-clip-photos\")\n","model = project.version(2).model\n","\n","# infer on a local image\n","print(model.predict(\"rclass_1.jpg\").json())\n","```\n","The sample python code above from Roboflow samples performs a request for classification according to the trained, [org311-clip model](https://universe.roboflow.com/borneo/org311-clip-photos/model/2)\n","\n","####Security Note\n","\n","**API_KEY** in order to secure the key value, for the purpose of this demo, the code above is wrapped in a proxy. The actual call you will run in the cell below calls the proxy rather than directly creating a project and a model to execute the call.\n","\n","Using a single line of code, the proxy securely appends the key, calling a REST endpoint for the image classification by Roboflow model.\n","```\n","await axios.post(`https://classify.roboflow.com/org311-clip-photos/2?api_key=${Config.api.ROBOFLOWKEY}`\n","```\n","\n"," (docs) [Roboflow images](https://blog.roboflow.com/what-is-image-classification/)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7056,"status":"ok","timestamp":1689642998739,"user":{"displayName":"Robert Rowntree","userId":"00753641935888348574"},"user_tz":420},"id":"hKUxNsBvsY8L","outputId":"a7c931aa-a28b-4a49-94f5-56e442da4b54"},"outputs":[{"name":"stdout","output_type":"stream","text":["{'class': 'garbage', 'confidence': 0.6178}\n","{'class': 'graffiti', 'confidence': 0.1363}\n"]}],"source":["import requests\n","\n","# Step 1: Read the file\n","filename = fname\n","with open(filename, \"rb\") as file:\n","    input = file.read()\n","\n","# Step 2: Construct the request and make the request\n","url = \"https://demo311-production.up.railway.app/imclass/photo.png\"\n","headers = {\"Content-Type\": \"application/octet-stream\"}\n","\n","resp = requests.post(url, data=input, headers=headers)\n","json_res = resp.json()\n","# print out the first 2 predictions for type of photo\n","ans = json_res[\"data\"][0]\n","#resp[\"predictions\"][0][\"predictions\"][0]\n","print(ans)\n","ans = json_res[\"data\"][1]\n","print(ans)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"WYNJVVyx1vDA"},"source":["## Repeat, select a different image for input\n","Then rerun the cells above, starting with **Select Input image**\n","Take a photo or go to your photo roll and select an image you know to contain location ie was taken while your camera's settings included ( Android setting \"use precise location\", IOS  your own phot..\n","Process this new input photo by rerunning each cell that follows the select input cell.\n","\n","The next notebook gets deeper into python features for interogating the image ( coordinates ), adding cloud storage for the photo ( AWS S3 ) and a issues database that can be queried using GPS methods such as **nearby**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HNyMTK-bU9Db"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/rowntreerob/demo311/blob/master/photoUpld.ipynb","timestamp":1694200424446},{"file_id":"https://github.com/rowntreerob/demo311/blob/master/photoUpld.ipynb","timestamp":1692890226592},{"file_id":"https://github.com/rowntreerob/sampleexpress/blob/master/photoUpld.ipynb","timestamp":1689371358010},{"file_id":"https://github.com/rowntreerob/sampleexpress/blob/master/photoUpld.ipynb","timestamp":1689008941759}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.16"}},"nbformat":4,"nbformat_minor":0}